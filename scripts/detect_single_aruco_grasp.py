# encoding: UTF-8
#!/usr/bin/env python3
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import cv2
import numpy as np
import time
import rospy
from pymycobot import MyCobot280, PI_PORT, PI_BAUD
from visualization_msgs.msg import Marker

# æ‘„åƒå¤´ä¸å¤¹çˆªçš„åç§»é‡ï¼ˆå¦‚æœéœ€è¦å¯å¾®è°ƒï¼‰
gripper_offset_y = -55
gripper_offset_x = 15

# åˆ‡æ¢æ§åˆ¶æ–¹å¼ï¼šTrue ä½¿ç”¨ send_coords()ï¼ŒFalse ä½¿ç”¨ send_angles()
USE_COORDS = False

class DetectArucoGrasp:
    def __init__(self):
        self.cache_x = self.cache_y = 0
        self.mc = MyCobot280(PI_PORT, PI_BAUD)

        print("ğŸ“¸ ç§»åŠ¨åˆ°æ¡Œé¢è§‚å¯Ÿåˆå§‹ä½å§¿")
        self.mc.send_angles([0, -30, 60, 0, 30, 0], 30)
        time.sleep(3.0)

        print("â¡ï¸ æ‰“å¼€å¤¹çˆªå‡†å¤‡æŠ“å–")
        self.mc.set_gripper_state(0, 80)
        time.sleep(1.0)

        # åˆå§‹åŒ–ç›¸æœº
        self.cap = cv2.VideoCapture(0)
        self.cap.set(3, 640)
        self.cap.set(4, 480)

        # ArUco å­—å…¸å’Œå‚æ•°
        self.aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_6X6_250)
        self.aruco_params = cv2.aruco.DetectorParameters_create()

        # âœ… ç›¸æœºå†…å‚çŸ©é˜µï¼ˆéœ€æ ¹æ®æ ‡å®šå€¼è°ƒæ•´ï¼‰
        self.camera_matrix = np.array([
            [781.33, 0., 347.53],
            [0., 783.79, 246.67],
            [0., 0., 1.]
        ])

        # ç›¸æœºç•¸å˜å‚æ•°
        self.dist_coeffs = np.array([[0.34, -2.52, -0.0012, 0.0067, 2.57]])

        rospy.init_node("aruco_single_grasp", anonymous=True)

    def xy_to_angles(self, x, y):
        # ğŸ‘‡ ç®€å•æ‹Ÿåˆï¼šå¯æ ¹æ®å®é™…æ¡Œé¢è°ƒæ•´å‚æ•°
        base = -x * 0.35
        shoulder = -15 + y * 0.25
        elbow = 60
        wrist = 0
        wrist_rot = 15
        hand = 0
        return [base, shoulder, elbow, wrist, wrist_rot, hand]

    def move_to_target(self, x, y):
        print(f"â¡ï¸ æ‰§è¡ŒæŠ“å–åŠ¨ä½œ @ ({x:.1f}, {y:.1f})")

        if USE_COORDS:
            approach = [x, y, 200, 178.99, -3.78, -62.9]
            grasp = [x, y, 65.5, 178.99, -3.78, -62.9]
            self.mc.send_coords(approach, 25, 0)
            time.sleep(2.5)
            self.mc.send_coords(grasp, 25, 0)
            time.sleep(2.5)
        else:
            # ä½¿ç”¨è§’åº¦æ–¹å¼æŠ“å–ï¼ˆç²—ç•¥æ‹Ÿåˆï¼‰
            angles = self.xy_to_angles(x, y)
            print(f"ğŸ”§ å‘é€æ‹Ÿåˆè§’åº¦: {angles}")
            self.mc.send_angles(angles, 30)
            time.sleep(3.0)

        print("ğŸ¤– é—­åˆå¤¹çˆªå¤¹å–ç›®æ ‡")
        self.mc.set_gripper_state(1, 80)
        time.sleep(1.5)

        print("âœ… æŠ“å–å®Œæˆ")

    def run(self):
        print("ğŸš€ å¼€å§‹æ£€æµ‹ ArUco ç›®æ ‡...")

        while cv2.waitKey(1) < 0:
            ret, img = self.cap.read()
            if not ret:
                print("âŒ æ— æ³•è·å–æ‘„åƒå¤´å›¾åƒ")
                break

            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            corners, ids, _ = cv2.aruco.detectMarkers(gray, self.aruco_dict, parameters=self.aruco_params)

            if ids is not None:
                print(f"âœ… æ£€æµ‹åˆ° ArUco ids: {ids.flatten()}")

                if 1 in ids:
                    index = list(ids.flatten()).index(1)
                    print(f"â¡ï¸ é€‰æ‹©ç›®æ ‡ ID = 1, index = {index}")

                    ret = cv2.aruco.estimatePoseSingleMarkers(corners, 0.03, self.camera_matrix, self.dist_coeffs)
                    tvec = ret[1][index][0]

                    x = round(tvec[0] * 1000, 2)
                    y = round(tvec[1] * 1000, 2)

                    print(f"ğŸ¯ ArUco ID 1 ä½å§¿åæ ‡ X = {x}, Y = {y}")
                    self.move_to_target(x, y)
                    break
                else:
                    print("âš ï¸ æ£€æµ‹åˆ°äº† ArUcoï¼Œä½†ä¸æ˜¯ ID=1")
            else:
                print("âš ï¸ æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½• ArUco æ ‡ç­¾")

            cv2.imshow("Aruco Detection", img)

if __name__ == '__main__':
    detect = DetectArucoGrasp()
    detect.run()
